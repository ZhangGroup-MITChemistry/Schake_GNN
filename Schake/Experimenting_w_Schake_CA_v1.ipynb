{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ef6d7d-a076-42f3-a619-f24f53633f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/airasj/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_cluster import radius_graph\n",
    "from torch_scatter import scatter_add, scatter\n",
    "import mdtraj\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafa150-0cb3-42a9-8dd9-dc542bfbe3be",
   "metadata": {},
   "source": [
    "Note, use root environment (base) for this notebook since pip doesn't appear to be installing PyTorch in a separate environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9ac557-c674-466b-9211-9b241cc23e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert True == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635853d-c2c2-4217-8f2b-67cd695ffae0",
   "metadata": {},
   "source": [
    "Check to ensure Apple Silicon GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a518b8c-ac14-47ed-9dd2-c6e9f6a999c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set user\n",
    "user = 'airasj'\n",
    "#user = 'mitadm'\n",
    "\n",
    "# Set pathway\n",
    "chig_path = '/Users/{}/OneDrive/MIT_Research/1st_Project/Small_Protein_MD/Datasets_MD/chignolin/MD/umbrella/CHARMM/c36_gbsa_hbond_constraint'.format(user)\n",
    "\n",
    "# Load chignolin pdb\n",
    "top = mdtraj.load('{}/parm_structs/chignolin_folded_avg_struct.pdb'.format(chig_path)).topology\n",
    "\n",
    "# Load chignolin trajectory\n",
    "umb_traj = torch.Tensor(mdtraj.load_netcdf('{}/chig_c36_gbn2_hbond_constraint_umb_100thou.nc'.format(chig_path), top).xyz)[0]\n",
    "umb_traj_2 = torch.cat([umb_traj, umb_traj])\n",
    "\n",
    "# Load umbrella energies\n",
    "umb_energies = torch.Tensor(np.load('{}/energies/chig_100thou_Ugbsa_umb.npy'.format(chig_path)))\n",
    "\n",
    "# Load atomic numbers (will use them as features) and partial charges\n",
    "umb_charges = torch.Tensor(np.load('/Users/{}/OneDrive/MIT_Research/1st_Project/Small_Protein_MD/Datasets_MD/chignolin/MD/explicit/chignolin_ptCharges_c36.npy'.format(user))).view(-1, 1)\n",
    "umb_elements = torch.Tensor(np.load('/Users/{}/OneDrive/MIT_Research/1st_Project/Small_Protein_MD/Datasets_MD/chignolin/MD/explicit/chignolin_elementsN_c36.npy'.format(user))).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5302a-d9f8-48b9-95a9-e78d09f4af9a",
   "metadata": {},
   "source": [
    "Get atom types from topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e287d7e9-29b6-492f-9a74-24735f7fd39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "tensor([63, 17, 19, 20,  1, 21,  2, 27, 26, 10,  4, 28,  7, 38, 14, 79, 53,  5,\n",
      "        32,  8, 39,  0, 72, 63, 17,  1, 21,  2, 27, 26, 10,  4, 28,  7, 38, 14,\n",
      "        79, 53,  5, 32,  8, 39,  0, 72, 63, 17,  1, 21,  2, 27, 26, 10, 73, 74,\n",
      "         0, 72, 63,  3, 36, 32,  1, 21,  2, 27, 26, 10, 52, 48,  0, 72, 63, 17,\n",
      "         1, 21,  2, 27, 26, 10, 52, 48,  3, 75, 76,  0, 72, 63, 17,  1, 21,  2,\n",
      "        24, 78, 44, 12, 49, 50, 51,  0, 72, 63, 17,  1, 23, 22,  0, 72, 63, 17,\n",
      "         1, 21,  2, 24, 78, 44, 12, 49, 50, 51,  0, 72, 63, 17,  1, 21,  2, 27,\n",
      "        26, 10,  4, 28, 67, 38,  8,  5,  9, 42, 16, 62, 15, 61, 13, 56,  0, 72,\n",
      "         0, 72, 80, 63, 17,  1, 21,  2, 27, 26, 10,  4, 28,  7, 38, 14, 79, 53,\n",
      "         5, 32,  8, 39])\n"
     ]
    }
   ],
   "source": [
    "umb_types = np.array([a.name for a in top.atoms])\n",
    "\n",
    "# Set all pairs\n",
    "all_types = np.array(['C', 'CA', 'CB', 'CD', 'CD1', 'CD2', 'CE', 'CE1', 'CE2', 'CE3', \n",
    "                      'CG', 'CG1', 'CG2', 'CH2', 'CZ', 'CZ2', 'CZ3', 'H', 'H1', 'H2', \n",
    "                      'H3', 'HA', 'HA2', 'HA3', 'HB', 'HB1', 'HB2', 'HB3', 'HD1', 'HD11', \n",
    "                      'HD12', 'HD13', 'HD2', 'HD21', 'HD22', 'HD23', 'HD3', 'HE', 'HE1', 'HE2',\n",
    "                      'HE21', 'HE22', 'HE3', 'HG', 'HG1', 'HG11', 'HG12', 'HG13', 'HG2', 'HG21',\n",
    "                      'HG22', 'HG23', 'HG3', 'HH', 'HH11', 'HH12', 'HH2', 'HH21', 'HH22', 'HZ',\n",
    "                      'HZ1', 'HZ2', 'HZ3', 'N', 'ND1', 'ND2', 'NE', 'NE1', 'NE2', 'NH1', \n",
    "                      'NH2', 'NZ', 'O', 'OD1', 'OD2', 'OE1', 'OE2', 'OG', 'OG1', 'OH', \n",
    "                      'OXT', 'SD', 'SG'])\n",
    "\n",
    "# Embed the types\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "embed = LabelEncoder()\n",
    "embed.fit(all_types)\n",
    "print(embed.transform(np.array(['CA'])))\n",
    "umb_embedding = torch.LongTensor(embed.transform(umb_types))\n",
    "print(umb_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c88fa8-8537-4b4e-bab9-22e27a198cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 frame sets\n",
    "coords_2 = torch.Tensor(mdtraj.load_netcdf('{}/chig_c36_gbn2_hbond_constraint_umb_100thou.nc'.format(chig_path), top).xyz)[:2]\n",
    "\n",
    "coords_2_list = []\n",
    "for coord in coords_2:\n",
    "    coords_2_list.append(coord)\n",
    "coords_2 = torch.cat(coords_2_list)\n",
    "\n",
    "batch_2_list = []\n",
    "for b in range(0,2):\n",
    "    batch_2 = torch.zeros(len(umb_charges), dtype=torch.long)+b\n",
    "    batch_2_list.append(batch_2)\n",
    "    \n",
    "batch_2 = torch.cat(batch_2_list)\n",
    "\n",
    "#charge_pairs_2 = torch.cat([charge_pairs, charge_pairs])\n",
    "umb_elements_2 = torch.cat([umb_elements, umb_elements])\n",
    "umb_embedding_2 = torch.cat([umb_embedding, umb_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e85b99-a94d-4fbf-b550-f43895ed9d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[  3,   4,   5,  ..., 121,  30,  39],\n",
      "        [  0,   0,   0,  ..., 165, 165, 165]])\n"
     ]
    }
   ],
   "source": [
    "# Set batch tensor\n",
    "batch = torch.cat([torch.zeros_like(umb_elements)+i for i in range(1)]).squeeze().type(torch.LongTensor)\n",
    "print(batch)\n",
    "\n",
    "# Compute edges for test frame\n",
    "edges = radius_graph(umb_traj, r=1, max_num_neighbors=100000)\n",
    "edges_2 = radius_graph(coords_2, r=1, batch=batch_2, max_num_neighbors=100000)\n",
    "edges_3 = radius_graph(coords_2[166:], r=1, batch=batch, max_num_neighbors=100000)\n",
    "print(edges)\n",
    "\n",
    "\n",
    "# Compute charge pairs\n",
    "#charge_pairs = umb_charges[edges[0]]*umb_charges[edges[1]]\n",
    "\n",
    "#umb_elements = umb_elements.to(mps_device)\n",
    "#coords = umb_traj.to(mps_device)\n",
    "#edges = edges.to(mps_device)\n",
    "#charge_pairs = charge_pairs.to(mps_device)\n",
    "#batch = torch.zeros(len(coords), dtype=torch.long).to(mps_device)\n",
    "#batch = torch.zeros(len(umb_traj), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87790ea3-a32e-42dc-84cc-a1e3698d0a0c",
   "metadata": {},
   "source": [
    "Test function for extracting edge batches, this can be used relatively quickly for normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94341d-5fe2-453d-8134-91cee3bcc970",
   "metadata": {},
   "source": [
    "### Test code from SAKE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c75574-1015-4936-a61d-02cd3f121ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import Schake_CA_model_v1 as Schake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc07c879-35e7-4567-bf30-02b1c5853ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vm/bq1z08v566qd7wd7n2nl_nxm0000gn/T/ipykernel_66045/3103476383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert True == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ad8ce-c844-491d-9410-90c719a00e29",
   "metadata": {},
   "source": [
    "Build the Schake model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cd5b646-5f72-415e-804f-e8781b8d617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sake_modular = Schake.create_Schake(hidden_channels = 32, \n",
    "                                    num_layers = 4, \n",
    "                                    kernel_size = 18,\n",
    "                                    cosine_offset = 0.5,\n",
    "                                    sake_low_cut = 0, \n",
    "                                    sake_high_cut = 0.5, \n",
    "                                    schnet_low_cut = 0.5, \n",
    "                                    schnet_high_cut = 2.5, \n",
    "                                    schnet_act = torch.nn.CELU(alpha=2.0), \n",
    "                                    sake_act = torch.nn.CELU(alpha=2.0), \n",
    "                                    out_act = torch.nn.CELU(alpha=2.0),\n",
    "                                    schnet_sel = 1,\n",
    "                                    #schnet_sel = None,\n",
    "                                    num_heads = 4, \n",
    "                                    embed_type = 'names', \n",
    "                                    num_out_layers = 3,\n",
    "                                    max_num_neigh = 10000,\n",
    "                                    normalize = False,\n",
    "                                    device = 'cpu')\n",
    "\n",
    "# Define function to edit a state dict\n",
    "def edit_stateDict(state_dict):\n",
    "        \n",
    "    # Define new dictionary\n",
    "    mod_dict = OrderedDict()\n",
    "        \n",
    "    # Define pattern to strip\n",
    "    pattern = re.compile('module.')\n",
    "        \n",
    "    # Loop through loaded state dict\n",
    "    for key, value in state_dict.items():\n",
    "        if re.search('module.', key):\n",
    "            mod_dict[re.sub(pattern, '', key)] = value\n",
    "        else:\n",
    "            mod_dict = state_dict\n",
    "\n",
    "    return mod_dict\n",
    "\n",
    "# Set statedict path\n",
    "stateDict_path = '/Users/airasj/OneDrive/MIT_Research/2nd_Project/Datasets/SwissProt/train_models/Schake/testing/energies_only/res400_8GPUs_4node_varBatch_32w_1nm/stateDicts/Schake_af2SP_epoch140.pt'\n",
    "\n",
    "# Load state dict for the model (parameters obviously won't be perfect matches for testing)\n",
    "stateDict = torch.load(stateDict_path, map_location = torch.device('cpu'))\n",
    "        \n",
    "# Modify the stateDict with correct names\n",
    "mod_stateDict = edit_stateDict(stateDict)\n",
    "        \n",
    "# Apply stateDict\n",
    "sake_modular.load_state_dict(mod_stateDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50b4ec-6d7b-40b1-91c1-62ef9a3ab629",
   "metadata": {},
   "source": [
    "Test modular SAKE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de7e9e47-9f10-4747-9762-5b521a838956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Time elapsed: 0.062 sec\n",
      "tensor(-2448.3525)\n",
      "------------------------\n",
      "Time elapsed: 0.061 sec\n",
      "tensor([-2448.3525, -4832.5327])\n",
      "------------------------\n",
      "Time elapsed: 0.036 sec\n",
      "tensor(-4832.5327)\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    #out = sake_modular(umb_elements.type(torch.LongTensor).squeeze(), umb_traj, batch=batch)\n",
    "    out = sake_modular(umb_embedding, umb_traj, batch=batch)\n",
    "    end = time.time()\n",
    "    print('------------------------')\n",
    "    print('Time elapsed: {:.3f} sec'.format(end-start))\n",
    "    print(out)\n",
    "    \n",
    "    start = time.time()\n",
    "    #out_2 = sake_modular(umb_elements_2.type(torch.LongTensor).squeeze(), coords_2, batch=batch_2)\n",
    "    out_2 = sake_modular(umb_embedding_2, coords_2, batch=batch_2)\n",
    "    end = time.time()\n",
    "    print('------------------------')\n",
    "    print('Time elapsed: {:.3f} sec'.format(end-start))\n",
    "    print(out_2)\n",
    "    \n",
    "    start = time.time()\n",
    "    #out_3 = sake_modular(umb_elements.type(torch.LongTensor).squeeze(), coords_2[166:], batch=batch)\n",
    "    out_3 = sake_modular(umb_embedding, coords_2[166:], batch=batch)\n",
    "    end = time.time()\n",
    "    print('------------------------')\n",
    "    print('Time elapsed: {:.3f} sec'.format(end-start))\n",
    "    print(out_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5588d-7193-4671-bbf8-4104a77f2e0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Examine outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4875305-f279-4131-b741-8c4cf90429c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f0cb2-5b32-4a38-b246-625572bae059",
   "metadata": {},
   "outputs": [],
   "source": [
    "umb_embedding[out[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c526f0-811a-4ba2-8091-d8219737f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "umb_embedding[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bd6b0-f84b-43d0-882e-231d529913d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(umb_types[101])\n",
    "print(umb_types[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc41b2-59b0-4580-ab2d-5138a7735f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(out[2][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374448df-1b64-481f-afa5-d3b94e25f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[1].min().sqrt())\n",
    "print(out[1].max().sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62d3cf-a5db-418c-977a-53162da8fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d15e8-6bae-4e50-a8ef-bf30b76174d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[2].min())\n",
    "print(out[2].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d341651-0a82-47dc-9539-72a465cb002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3df552-c150-4586-a54e-ef082c2af3c7",
   "metadata": {},
   "source": [
    "Examine RBFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0f463-1520-4a67-a7b1-d6b2262fdb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d1213-fa25-4204-a960-0f3f50e9930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5ca41-7f72-4844-a3b3-b4bb8160ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert True == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32475bd-7041-40a0-befc-4c346b93e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('rbfs/rbf_expnorm_sqrt_diff_end.npy', out[4].numpy(), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd872791-5615-445e-8c3d-29313cebba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rbfs/SAKE_rbf_expnorm_sqrt_1nm.npy', out[3].numpy(), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6adc41-3309-45f7-b8ad-51d25b1b4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e81c8-ebf0-41d7-b4ca-d4158063b61e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Note on RBF and cosine cutoff functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659b7831-f2c2-4cca-9e2f-e9038aef9992",
   "metadata": {},
   "source": [
    "- Cosine cutoff\n",
    "    - SAKE -> the cosine cutoff starts at 0, ends at fixed point of $2 r_\\mathrm{cut}^\\mathrm{SAKE}$. B/c the SAKE cutoff is set to 0.5 nm here, the minimum value for the cosine cutoff is 0.5. B/c the cutoff now needs to closely align with the offsetted cutoff for the SAKE layer, we simply input $r$ rather than $r^2$ for simplicity. The function is as follows:\n",
    "    $\\frac{1}{2} \\left( \\cos \\left[ \\frac{\\pi r}{2 r_\\mathrm{cut}^\\mathrm{SAKE}} \\right] + 1 \\right)$\n",
    "    - SchNet -> B/c the cutoff distance for SchNet is so much larger now, can't use the same cutoff function as from SAKE. As such, the function has been modified as follows: \n",
    "    $ \\frac{1}{4} \\left( \\cos \\left[ \\frac{\\pi \\left( r - \\mathrm{offset} \\right)}{r_\\mathrm{cut}^\\mathrm{SchNet} - \\mathrm{offset}} \\right] + 1 \\right)$.\n",
    "    This modification provides more coverage of the entire range of alpha carbons that SchNet can process.\n",
    "\n",
    "- RBF function\n",
    "    - SAKE -> like with the original Schake, the expnorm function is used with a start of 0 nm, and a fixed endpoint of $2 \\left( r_\\mathrm{cut}^\\mathrm{SAKE} \\right)^2$ (despite the fact that this point will never be reached). $r^2$ is inputted to the model rather than $r$, as in the original formulation. Note that setitng the endpoint to $2 \\left( r_\\mathrm{cut}^\\mathrm{SAKE} \\right)^2$ ensures that the RBF will behave consistently with the original Schake\n",
    "    - SchNet -> like with the original Schake, the expnorm function is used with a start of 0 nm (despite the fact that this 0 nm point will never be reached) and an endpoint of $r^\\mathrm{SchNet}_\\mathrm{cut}$. Like the original Schake, $r$ is inputted to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0c32b-60c9-4c29-a054-2b041de09bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1\n",
    "0.5*(torch.cos(torch.tensor(math.pi)*r)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54927d5b-8d7f-4d0a-8a6e-459b33a4f1f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Compute number of pairs for benchmark dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d833d2e6-8d9a-43ca-a212-b1caec51c0d6",
   "metadata": {},
   "source": [
    "Goal here is to examine the total number of atom pairs produced from the benchmark dataset so that we can try and determine a good cutoff distance to use for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbe7a67d-56e4-44c2-926b-24f957c9fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/airasj/OneDrive/MIT_Research/2nd_Project/Datasets/SwissProt/python')\n",
    "import dataset_prep\n",
    "\n",
    "# Load dataset\n",
    "bench_dataset = torch.load('/Users/airasj/OneDrive/MIT_Research/2nd_Project/Figures/benchmark_figures/SPAF_dataset_bench_big.pt')\n",
    "\n",
    "# Loop through dataset, get num of atoms\n",
    "num_atoms, entries = [], []\n",
    "for data in bench_dataset:\n",
    "    num_atoms.append(data[-2].item())\n",
    "    entries.append(data[-1].item())\n",
    "    \n",
    "# Conver to numpy array\n",
    "num_atoms = np.array(num_atoms)\n",
    "entries = np.array(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408387c-6dca-4378-83fd-ce806bc20b5f",
   "metadata": {},
   "source": [
    "Loop through the benchmarking dataset to get number of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f4c0923-715d-4227-91de-169ccab1c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord2radial(edge_index, coord):\n",
    "    row, col = edge_index\n",
    "    coord_diff = coord[row] - coord[col]\n",
    "    radial = torch.sum(coord_diff**2, 1).unsqueeze(1)\n",
    "\n",
    "    return radial, coord_diff\n",
    "\n",
    "# SAKE cutoff\n",
    "sake_cut = 0.5  # -> this is 0.5 nm\n",
    "schnet_cut = 2.5\n",
    "#h_sel = 1\n",
    "h_sel = None\n",
    "\n",
    "sake_pairs, schnet_pairs = [], []\n",
    "other_schnet_pairs = []\n",
    "for data in bench_dataset:\n",
    "# Generate adjacency lists\n",
    "    edges = radius_graph(data[0], \n",
    "                         r=schnet_cut, # This can be different depending on which model\n",
    "                         batch=torch.zeros(data[-2], dtype=torch.long), \n",
    "                         max_num_neighbors=10000\n",
    "                        )\n",
    "\n",
    "    # Compute pairwise distances and edge vectors\n",
    "    radial, coord_diff = coord2radial(edges, data[0])\n",
    "\n",
    "    # Compute distances (sqrt of radial)\n",
    "    dist = torch.sqrt(radial)\n",
    "\n",
    "    # Filter edges, coord_diff, radial, dist, rbf based on individual cutoffs\n",
    "    sake_mask = torch.where((dist < sake_cut) & (dist >= 0))[0]\n",
    "    schnet_mask = torch.where((dist >= sake_cut) & (dist <= schnet_cut))[0]\n",
    "\n",
    "    # Reshape the edges, extract only necessary edges for each model\n",
    "    sake_edges = edges.T[sake_mask].T\n",
    "    schnet_edges = edges.T[schnet_mask].T\n",
    "\n",
    "    # Extract radial, coord_diff for SAKE pairs only\n",
    "    sake_radial, sake_coord_diff = radial[sake_mask], coord_diff[sake_mask]\n",
    "\n",
    "    # Extract distance for SchNet pairs only\n",
    "    schnet_dist = dist[schnet_mask]\n",
    "    \n",
    "    if h_sel != None:\n",
    "        # For SchNet pairs, create adjacency list in terms of species\n",
    "        h_schnet_edges = data[-3][schnet_edges]\n",
    "\n",
    "        # Filter SchNet edges to only include atom type of interest\n",
    "        h_mask = torch.where(h_schnet_edges[0] == h_sel)[0]\n",
    "        schnet_edges = schnet_edges.T[h_mask].T\n",
    "    \n",
    "    # Append number of pairs to list\n",
    "    sake_pairs.append(sake_edges.shape[-1])\n",
    "    schnet_pairs.append(schnet_edges.shape[-1])\n",
    "    # Check to see number of pairs when other adjacency list used\n",
    "    other_schnet_pairs.append(torch.where(h_schnet_edges[1] == 1)[0].shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d78b7d5-a75e-4266-9579-beca19a07627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27864150 29276034  5740080 34216242 33934474 27630380 33760678 17072840\n",
      " 32863462 20193182]\n",
      "[1368804 1368804 1368804 1368804 1368804 1368804 1368804 1368804 1368804\n",
      " 1368804]\n"
     ]
    }
   ],
   "source": [
    "start = 510\n",
    "stop = start + 10\n",
    "print(np.array(schnet_pairs)[start:stop])\n",
    "print(np.array(other_schnet_pairs)[start:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db1c0dfe-f50d-4f6e-8372-d171d9c4d632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(np.array(schnet_pairs), np.array(other_schnet_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c9973-b71c-494f-ba01-3624c0a1b267",
   "metadata": {},
   "source": [
    "As structures get bigger, there starts to be a discrepancy between the adjacency lists. This isn't a major problem, but it is interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331703a-c883-46f5-8b27-3e634e230111",
   "metadata": {},
   "source": [
    "Save the number of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7d1ead9-2375-488f-bf25-ce60935e7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('schake_pair_analysis/schake_sake_pairs.npy', np.array(sake_pairs))\n",
    "np.save('schake_pair_analysis/schake_schnet_pairs.npy', np.array(schnet_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9faa8ac0-bb4b-416b-92e0-b012ef9c042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('schake_pair_analysis/num_atoms.npy', num_atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5a849-dcd7-4b0b-bc24-027360531644",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get info to create figure displaying how Schake-C$\\alpha$ works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da698bc-e41e-4d52-9ed0-4aa265f1babf",
   "metadata": {},
   "source": [
    "Get list of pairs for A1W0R3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf2dc66-2c39-4c19-8554-4953d7696019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(bench_dataset[293][-2], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40686d18-3874-4fe9-9e74-09dad64290e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Time elapsed: 3.468 sec\n",
      "tensor(49464496.)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    out = sake_modular(bench_dataset[293][-3], bench_dataset[293][0], batch=torch.zeros(bench_dataset[293][-2], dtype=torch.long))\n",
    "    end = time.time()\n",
    "    print('------------------------')\n",
    "    print('Time elapsed: {:.3f} sec'.format(end-start))\n",
    "    print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552b863-fb66-4c64-96ad-b0f92d41655f",
   "metadata": {},
   "source": [
    "#### Create pair fraction figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a43ba-1024-4d68-8080-a1a0fd60bee2",
   "metadata": {},
   "source": [
    "Load the pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2926f3-0a8e-4ca3-a521-4ef82512988e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GNN]",
   "language": "python",
   "name": "conda-env-GNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
